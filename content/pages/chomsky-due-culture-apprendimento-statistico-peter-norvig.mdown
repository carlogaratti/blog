Date: 01 Jul 2012
Summary:

# Su Chomsky e le due culture dell'apprendimento statistico #

_Questo post è una traduzione di ["On Chomsky and the Two Cultures of Statistical Learning"][] di Peter Norvig._

Technology Review [sostiene][] che al simposio dal titolo 
["Brain, Minds, and Machines"][] tenuto in occasione dei 150 anni del MIT il
professor Noam Chomsky

> ha deriso i ricercatori in apprendimento automatico che usano metodi
> puramente statistici per produrre comportamenti che imitino qualcosa di
> esistente nel mondo, ma che non provano a comprendere il significato di tali
> comportamenti.

Ora è disponibile la [trascrizione][], perciò citiamo Chomsky stesso:

> È vero che è stato fatto un sacco di lavoro nel provare ad applicare modelli
> statistici a svariati problemi linguistici. Penso che ci sia stato qualche
> successo, ma molti fallimenti. Esiste una nozione di successo ... che penso
> si sia vista per la prima volta nella storia della scienza. Chiamano 
> "successo" l'aver approssimato dati non ancora analizzati.

Questo post discute le affermazioni di Chomsky, specula su quello che avrebbe
potuto intendere e prova a determinarne fondatezza e importanza.

Le osservazioni di Chomsky erano in risposta alla domanda di Steven Pinker sui
successi ottenuti dai modelli probabilistici addestrati con metodi statistici.

1. Cosa intendeva Chomsky? Ha ragione?
2. Cosa è un modello statistico?
3. Quanto successo hanno avuto i modelli statistici del linguaggio?
4. Esiste una nozione comparabile di successo nella storia della scienza?
5. Cosa non piace a Chomsky dei modelli statistici?

## Cosa intendeva Chomsky? Ha ragione? ##

Penso che gli argomenti di Chomsky siano i seguenti:

1. I modelli statistici del linguaggio hanno avuto un successo in senso
ingegneristico, ma questo è irrilevante per la scienza.

2. Modellare accuratamente fatti linguistici è come collezionare farfalle;
ciò che conta nella scienza (e in particolare nella linguistica) sono i
principi sottostanti.

3. I modelli statistici sono incomprensibili; non sono di aiuto
all'intuizione.

4. I modelli statistici possono simulare accuratamente certi fenomeni, ma la
simulazione è fatta in modo totalmente sbagliato; le persone non decidono
quale dovrebbe essere la terza parola di una frase consultando una tabella di
probabilità TODO

5. I modelli statistici si sono dimostrati incapaci di apprendere il
linguaggio; dunque il linguaggio deve essere innato, perciò perché questi
modellatori statistici stanno sprecando il proprio tempo in uno sforzo
sbagliato?

Ha ragione? Questo è un dibattito di lunga data. Di seguito le mie risposte:

1. Sono d'accordo che il successo ingegneristico non sia l'obiettivo o la
misura di buona scienza. Osservo però che la scienza e l'ingegneria si 
sviluppano insieme, e che il successo ingegnerestico indica che qualcosa
sta andando per il verso giusto, perciò è un indizio (ma non una prova) di
un modello scientifico di successo.

2. La scienza è una combinazione di raccolta di dati e formulazione di teorie;
nessuna delle due attività può procedere da sola. Penso che Chomsky abbia 
torto nel far pendere la bilancia a favore della teoria a discapito della
raccolta di dati; nella storia della scienza, TODO

3. Sono d'accordo che sia difficile comprendere un modello contenente miliardi
di parametri. Sicuramente un uomo non può capire un tale modello andando a
indagare individualmente i valori di ogni parametro. Ma si può guadagnare in
intuizione esaminando le _proprietà_ del modello — dove ha successo e dove fallisce, quanto bene impara in funzione dei dati, eccetera.

4. Sono d'accordo che un modello Markoviano di probabilità delle singole
parole non può modellare l'intero linguaggio. È ugualmente vero che un conciso
modello ad albero privo di probabilità non può modellare l'intero linguaggio.
Serve un modello probabilistico che copra parole, alberi, semantica, contesti,
discorsi, eccetera. Chomsky rigetta tutti i modelli probabilistici per via
delle mancanze di particolari modelli di 50 anni fa. Capisco come Chomsky,
partendo dalla studio della generazione del linguaggio, arrivi alla 
conclusione che i modelli probabilistici non siano necessari. Ma la stragrande
maggioranza delle persone che studiano compiti di _interpretazione_, come il
riconoscimento della voce, TODO

5. Nel 1967 il teorema di Gold mostrò alcune limitazioni teoriche sulla
deduzione logica di linguaggi formali. Ma questo risultato non ha niente a che 
vedere con il compito affrontato da chi impara un linguaggio naturale. In ogni
caso, nel 1969 sapevamo già, grazie a Horning, che l'inferenza probabilistica 
di grammatiche libere da contesto non soffre di tale limitazione. Sono 
d'accordo con Chomsky che sia innegabile che gli uomini possiedano una 
capacità naturale di imparare il linguaggio naturale, ma non sappiamo 
abbastanza di questa capacità per escluderne rappresentazioni probabilistiche 
o apprendimento statistico. Penso che sia molto più probabile che 
l'apprendimento del linguaggio umano comporti qualcosa simile all'inferenza 
probabilistica o statistica, ma non lo sappiamo ancora.

Consentitemi ora di giustificare le mie risposte con uno sguardo più attento
alle restanti domande.

## Cosa è un modello statistico? ##

Un **modello statistico** è un modello matematico modificato o addestrato 
dall'aggiunta di dati. I modelli statistici sono spesso, ma non sempre,
probabilistici. Dove è importante distinguere saremo attenti a non dire
soltanto "statistico", ma useremo i seguenti lemmi:

  + Un **modello matematico** specifica una relazione fra variabili, sia in 
  una forma funzionale TODO
  + Un **modello probabilistico** TODO
  + Un **modello addestrato** TODO

Ad esempio, un decennio prima di Chomsky, Claude Shannon [propose modelli
probabilistici della comunicazione][] basati su catene di Markov di parole. Se
avete un vocabolario di $100000$ parole e un modello di Markov del secondo
ordine (cioè in cui la probabilità di una parola dipende dalle precedenti
due), avrete bisogno di specificare $10^ {15}$ probabilità per determinare il
modello. L'unica maniera fattibile per imparare questi $10^ {15}$ parametri
consiste nel raccogliere statistiche dai dati e usare un qualche metodo di
approssimazione per i molti casi in cui non esistono dati. Perciò molti, ma
non tutti, modelli probabilistici sono addestrati. Inoltre molti, ma non
tutti, modelli addestrati sono probabilistici.

Come ulteriore esempio, consideriamo il modello Newtoniano dell'attrazione
gravitazionale, il quale afferma che la forza fra due oggetti di masse $m_1$ e
$m_2$ a distanza $r$ sia data da

TODO

TODO

TODO

TODO

## Quanto successo hanno avuto i modelli statistici del linguaggio? ##

Chomsky ha detto chi i modelli statistici hanno avuto un successo limitato in
certe aree applicative. Andiamo a vedere come i computer approcciano il
linguaggio, e definiamo "successo" come "fare previsioni accurate sul mondo"
Prima ancora le maggiori aree applicative:

  + **Motori di ricerca** TODO
  + TODO
  + **Traduzione automatica** TODO
  + TODO

Ora invece volgiamo l'attenzione alle parti che sono d'interesse per il
linguista computazionale e non l'utente tipico:

  + TODO
  + TODO
  + TODO
  + TODO

Chiaramente non è accurato dire che i modelli statistici (e probabilistici)
hanno ottenuto un successo _limitato_; piuttosto hanno raggiunto una posizione
_dominante_ (ma non esclusiva).

TODO

TODO

TODO

TODO

## Esiste una nozione comparabile di successo nella storia della scienza? ##

Quando Chomsky ha detto _"Questa è una nozione di successo scientifico che
è totalmente nuova. Non conosco niente di simile nella storia della scienza"_
intendeva che TODO

Una [definizione da dizionario][] della scienza è "Lo studio sistematico della
struttura e del comportamento del mondo fisico e naturale attraverso 
osservazioni e esperimenti", il che enfatizza TODO

> TODO

Sembra proprio che questo articolo si concentri sul "modellare accuratamente
la realtà" piuttosto che "aiutare l'intuizione". TODO

Poi ho guardato a tutti i titoli e abstract del [numero corrente][1] di 
_Science_:

  + TODO
  + TODO
  + TODO

e poi ho fatto lo stesso per il [numero corrente][2] di _Cell_:

  + TODO
  + TODO
  + TODO
  
e infine per i [Premi Nobel 2010][] nelle scienze:

  + Fisica: TODO
  + Chimica: TODO
  + Fisiologia o Medicina: TODO

La mia conclusione è che il 100% di questi premi e articoli riguardano più che
altro "modellare accuratamente il mondo" piuttosto che "aiutare l'intuizione",
sebbene tutti TODO

## Cosa non piace a Chomsky dei modelli statistici? ##

Ho detto che i modelli statistici vengono talvolta confusi con i modelli
probabilistici; consideriamo dunque in quale misura le obiezioni di Chomsky
siano piuttosto rivolte verso i modelli probabilistici. È ben noto che nel 
1969 [abbia scritto][]:

> Ma deve essere riconosciuto che la nozione di "probabilità di una frase" sia
> interamente inutile, sotto qualunque sua interpretazione.

Il suo argomento principale era che TODO

> Penso che siamo costretti a concludere che ... i metodi probabilistici TODO

TODO

1. TODO
2. TODO
3. TODO
4. TODO

TODO

TODO

TODO

> Nè (a) 'colorless green ideas sleep furiosly' nè (b) 'furiosly sleep ideas
> green colorless', o una qualunque delle loro parti, sono mai apparse nell'
> esperienza linguistica di chi parla inglese. Ma (a) è grammaticalmente
> corretta, (b) no.

TODO

  + TODO
  + TODO
  + "**Ideas sleep** in books." [Current Opinion: Volume 52][], (1912)

TODO

TODO

TODO

TODO

1. The earth quaked.
2. ? It quaked her bowels

TODO

TODO

TODO

TODO

TODO

TODO

## Le due culture ##

TODO

## Bibliografia annotata ##

1. Abney, Steve (1996) [Statistical Methods and Linguistics][], in Klavans e Resnick (ed.) _The Balancing Act: Combining Symbolic and Statistical Approaches to Language_, MIT Press.
   > TODO
   
2. TODO
   > TODO
   
3. TODO
   > TODO
   
4. TODO
   > TODO
   
5. TODO
   > TODO
   
6. TODO
   > TODO
   
7. TODO
   > TODO
   
8. TODO
   > TODO
     
9. TODO
   > TODO
   
10. TODO
    > TODO

11. TODO
    > TODO

12. TODO
    > TODO

13. TODO
    > TODO

14. TODO
    > TODO

15. TODO
    > TODO

16. Platone (c. 380AC) [La Repubblica][]
    > Qui citato per il mito della caverna.

17. TODO

["On Chomsky and the Two Cultures of Statistical Learning"]: http://norvig.com/chomsky.html

[sostiene]: http://www.technologyreview.com/computing/37525/?a=f
["Brain, Minds, and Machines"]: http://mit150.mit.edu/symposia/brains-minds-machines
[trascrizione]: http://languagelog.ldc.upenn.edu/myl/PinkerChomskyMIT.html
[propose modelli probabilistici della comunicazione]: http://cm.bell-labs.com/cm/ms/what/shannonday/shannon1948.pdf

[abbia scritto]: http://books.google.com/books?id=iaXVXYDQN1oC&pg=PA296&dq=%22probability+of+a+sentence%22+%22entirely+useless%22&hl=en&ei=_s7eTc_5DrTciALcsvnlCg&sa=X&oi=book_result&ct=result&resnum=4&ved=0CDoQ6AEwAw#v=onepage&q=%22probability%20of%20a%20sentence%22%20%22entirely%20useless%22&f=false
[Current Opinion: Volume 52]: http://books.google.com/books?id=fTciAQAAIAAJ&pg=PA96&dq=%22ideas+sleep%22&hl=en&ei=bZrcTePRBeHmiAKp2fHoDw&sa=X&oi=book_result&ct=result&resnum=3&sqi=2&ved=0CDoQ6AEwAg#v=onepage&q=%22ideas%20sleep%22&f=false

[Statistical Methods and Linguistics]: http://www.vinartus.net/spa/95c.pdf

[La Repubblica]: http://en.wikipedia.org/wiki/Allegory_of_the_Cave